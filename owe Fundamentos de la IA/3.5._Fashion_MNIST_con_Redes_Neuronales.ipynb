{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmXnTH0svS6+NLeI1iDLCF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Un problema de visión artificial mediante redes neuronales\n","\n","### Planteamiento\n","\n","En este cuaderno vamos a resolver un problema de visión artificial. Construiremos una red neuronal capaz de recibir una fotografía de una prenda de ropa e indicarnos a cual de las siguientes diez categorías pertenece:\n","\n","1. Camisetas\n","2. Pantalones\n","3. Jerseys\n","4. Vestidos\n","5. Abrigos\n","6. Sandalias\n","7. Camisas\n","8. Zapatillas de deporte\n","9. Bolsos\n","10. Botines\n","\n","Para construir esta red neuronal emplearemos Keras: el marco de trabajo con redes neuronales diseñado por Google.\n","\n","### Breve exploración de los datos\n","\n","Comenzamos cargando el conjunto de datos. El conjunto de datos Fashion MNIST es uno de los más usados como iniciación a la Visión Artificial y se encuentra integrado dentro de Keras:\n"],"metadata":{"id":"k0ZxdUKB0nWF"}},{"cell_type":"code","source":["from keras.datasets import fashion_mnist\n","\n","(imagenes_entrenamiento, etiquetas_entrenamiento), (imagenes_test, etiquetas_test) = fashion_mnist.load_data()"],"metadata":{"id":"QbofznQ01h9x","executionInfo":{"status":"ok","timestamp":1695320643586,"user_tz":-120,"elapsed":11219,"user":{"displayName":"AN","userId":"07770316912620247459"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2dee3174-66c8-4b17-e5cc-699d8c3f2559"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 1us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 2s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"markdown","source":["Empleamos el atributo `shape` para ver el tamaño de nuestros datos:"],"metadata":{"id":"-8zOy_ff17hl"}},{"cell_type":"code","source":["imagenes_entrenamiento.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXP4FosY1wdX","executionInfo":{"status":"ok","timestamp":1695320690443,"user_tz":-120,"elapsed":526,"user":{"displayName":"AN","userId":"07770316912620247459"}},"outputId":"74f76392-71e8-4ef5-b0a1-0d1ee1f240d7"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["etiquetas_entrenamiento.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAEFjDtt2FRd","executionInfo":{"status":"ok","timestamp":1695320707541,"user_tz":-120,"elapsed":4,"user":{"displayName":"AN","userId":"07770316912620247459"}},"outputId":"2124df00-0a0e-4da8-8215-41ac50a8eb3f"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000,)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["imagenes_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ea-QalGS2Ho7","executionInfo":{"status":"ok","timestamp":1693767040472,"user_tz":-120,"elapsed":2,"user":{"displayName":"AN","userId":"07770316912620247459"}},"outputId":"1b81e7df-4219-4c54-e526-3ae7cbc7ba83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 28, 28)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["etiquetas_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUGssF3I2K-T","executionInfo":{"status":"ok","timestamp":1693767040867,"user_tz":-120,"elapsed":2,"user":{"displayName":"AN","userId":"07770316912620247459"}},"outputId":"d113f1fc-f047-4c5d-9547-65d8ff0c1159"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000,)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["Podemos probar a visualizar alguna de estas imágenes. Si observamos el dato veremos que es una matriz de números:"],"metadata":{"id":"JBkaoGbm-nJN"}},{"cell_type":"code","source":["prenda = imagenes_entrenamiento[5]"],"metadata":{"id":"u0vrKO09-p2X","executionInfo":{"status":"ok","timestamp":1695320725402,"user_tz":-120,"elapsed":344,"user":{"displayName":"AN","userId":"07770316912620247459"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Podemos visualizar este conjunto de datos como una imagen usando el módulo matplotlib:"],"metadata":{"id":"jWgGVXdd-y4d"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.imshow(prenda, cmap=plt.cm.binary)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"Rc_ThpSe-z8u","executionInfo":{"status":"ok","timestamp":1695320733449,"user_tz":-120,"elapsed":828,"user":{"displayName":"AN","userId":"07770316912620247459"}},"outputId":"b21e0ca8-7c6f-4e6a-f1e3-3ec6b0e50204"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Para estandarizar los datos (buena práctica a la hora de trabajar con redes neuronales) vamos a hacer que todos los valores con los que trabajemos se encuentren entre 0 y 1:"],"metadata":{"id":"qWqbui3M5ZPb"}},{"cell_type":"code","source":["imagenes_entrenamiento = imagenes_entrenamiento.reshape((60000, 28 * 28))\n","imagenes_entrenamiento = imagenes_entrenamiento.astype('float32') / 255\n","imagenes_test = imagenes_test.reshape((10000, 28 * 28))\n","imagenes_test = imagenes_test.astype('float32') / 255"],"metadata":{"id":"w9GwC6pj5jtd","executionInfo":{"status":"ok","timestamp":1695320805540,"user_tz":-120,"elapsed":451,"user":{"displayName":"AN","userId":"07770316912620247459"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Además convertiremos las etiquetas en variables categóricas para que el modelo entienda que tiene que predecir categorías y no aplique razonamientos numéricos, por ejemplo, que como 8 es zapatillas de deporte y 10 botines, los bolsos (9) son un punto intermedio entre ambos:"],"metadata":{"id":"NSLWc4g_50ZZ"}},{"cell_type":"code","source":["from keras.utils import to_categorical\n","etiquetas_entrenamiento = to_categorical(etiquetas_entrenamiento)\n","etiquetas_test = to_categorical(etiquetas_test)"],"metadata":{"id":"H9r2_5cK6Dgn","executionInfo":{"status":"ok","timestamp":1695320817327,"user_tz":-120,"elapsed":362,"user":{"displayName":"AN","userId":"07770316912620247459"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Resolución del problema"],"metadata":{"id":"iqHGRKrV5PFK"}},{"cell_type":"markdown","source":["Una vez que tenemos cargados los datos con los que vamos a trabajar procedemos a construir la artquitectura de la red neuronal. Planteamos una red neuronal con dos capas:\n","\n","1. Una capa con 512 neuronas que procesarán toda la información.\n","2. Una capa final con diez neuronas, una por cada categoría que deseamos predecir.\n","\n","La idea es que cada neurona de la última capa prediga la probabilidad de cada categoría, es decir, la primera neurona indicará la probabilidad de que se trate de una camiseta, la segunda de un pantalón y así sucesivamente.\n","\n","Para construir la arquitectura de la red simplemente generaremos un modelo y le asociaremos dos capas:"],"metadata":{"id":"avJB_tVV2TTN"}},{"cell_type":"code","source":["from keras import models\n","from keras import layers\n","\n","red_neuronal = models.Sequential() # indicamos que vamos a construir un modelo secuencial\n","red_neuronal.add(layers.Dense(512, activation='relu', input_shape=(28*28,))) # añadimos la primera capa con 512 neuronas, una función de activación y la forma de los datos de entrada\n","red_neuronal.add(layers.Dense(10, activation=\"softmax\"))"],"metadata":{"id":"fFNokeOk2Mgy","executionInfo":{"status":"ok","timestamp":1695320937650,"user_tz":-120,"elapsed":745,"user":{"displayName":"AN","userId":"07770316912620247459"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["__Nota.__ Las funciones de activación de cada capa indican qué transformaciones matemáticas sufrirán los datos al terminar de atravesar dicha capa. Al fin y al cabo podemos pensar en cada capa como una transformación y un filtro de datos.\n","\n","Con estas dos líneas hemos construido la arquitectura de nuestra primera red neuronal. Una vez hecho esto debemos compilar el modelo, es decir, darle las indicaciones necesarias para que pueda ser entrenado.\n","\n","Al compilar el modelo el indicaremos qué tipo de optimizador utilizar, qué función de pérdida y qué métricas deseamos monitorizar.\n","\n","Cuando abordamos un problema de aprendizaje profundo siempre estaremos en el fondo abordando un problema de optimización. En este caso buscamos el modelo que menos se equivoque al realizar las predicciones sobre las prendas, por eso debemos definir un optimizador y una función de pérdida que buscamos reducir. La métrica será una medida que nos interese monitorizar, en este caso por ejemplo monitorizaremos la tasa de acierto:"],"metadata":{"id":"jwHz5A7B3bYw"}},{"cell_type":"code","source":["red_neuronal.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"],"metadata":{"id":"o0oV0hTi3amo","executionInfo":{"status":"ok","timestamp":1695320999308,"user_tz":-120,"elapsed":527,"user":{"displayName":"AN","userId":"07770316912620247459"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Nuestra arquitectura ya está diseñada y nuestra red compilada por lo que ya estamos listos para entrenar nuestra primera red neuronal. Para ello simplemente alimentaremos el modelo con imágenes y sus etiquetas. Además le indicaremos cuántas iteraciones (epochs) queremos que haga, es decir, cuántas veces queremos que repase los datos y un tamaño de lote (batch size) que hace referencia a cuántas imágenes van a procesarse de cada vez:"],"metadata":{"id":"RjrjKvFs6Mv3"}},{"cell_type":"code","source":["red_neuronal.fit(imagenes_entrenamiento, etiquetas_entrenamiento, epochs=25, batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFMafdQ15JGP","executionInfo":{"status":"ok","timestamp":1695321185890,"user_tz":-120,"elapsed":143156,"user":{"displayName":"AN","userId":"07770316912620247459"}},"outputId":"269b7b57-d6a6-45fe-e62a-7aae37369ea3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","469/469 [==============================] - 6s 11ms/step - loss: 0.5634 - accuracy: 0.8003\n","Epoch 2/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.3878 - accuracy: 0.8590\n","Epoch 3/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.3399 - accuracy: 0.8753\n","Epoch 4/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3118 - accuracy: 0.8844\n","Epoch 5/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2938 - accuracy: 0.8909\n","Epoch 6/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2784 - accuracy: 0.8972\n","Epoch 7/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2650 - accuracy: 0.9010\n","Epoch 8/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2543 - accuracy: 0.9057\n","Epoch 9/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2447 - accuracy: 0.9092\n","Epoch 10/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2356 - accuracy: 0.9123\n","Epoch 11/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2267 - accuracy: 0.9159\n","Epoch 12/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2171 - accuracy: 0.9196\n","Epoch 13/25\n","469/469 [==============================] - 6s 12ms/step - loss: 0.2110 - accuracy: 0.9210\n","Epoch 14/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2049 - accuracy: 0.9239\n","Epoch 15/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1987 - accuracy: 0.9258\n","Epoch 16/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1916 - accuracy: 0.9290\n","Epoch 17/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1869 - accuracy: 0.9304\n","Epoch 18/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1810 - accuracy: 0.9335\n","Epoch 19/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1768 - accuracy: 0.9349\n","Epoch 20/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1726 - accuracy: 0.9356\n","Epoch 21/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1668 - accuracy: 0.9381\n","Epoch 22/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1647 - accuracy: 0.9388\n","Epoch 23/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1570 - accuracy: 0.9420\n","Epoch 24/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1524 - accuracy: 0.9448\n","Epoch 25/25\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1516 - accuracy: 0.9448\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bc3db2bd090>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["¡Ya tenemos nuestro modelo construido y entrenado! Vamos a evaluar cómo de bien nos ha ido:"],"metadata":{"id":"nVSzANJm9tZG"}},{"cell_type":"code","source":["perdida_test, acierto_test = red_neuronal.evaluate(imagenes_test, etiquetas_test)\n","print('Nuestro modelo acierta en el conjunto de evaluación en un porcentaje de:', acierto_test * 100, \"%.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o84sGALe6s1e","executionInfo":{"status":"ok","timestamp":1695321215129,"user_tz":-120,"elapsed":1225,"user":{"displayName":"AN","userId":"07770316912620247459"}},"outputId":"b0edae0e-9452-4a8e-fee5-8030bc90ad14"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8889\n","Nuestro modelo acierta en el conjunto de evaluación en un porcentaje de: 88.88999819755554 %.\n"]}]},{"cell_type":"markdown","source":["Con estas pocas líneas de código hemos sido capaces de construir y entrenar un modelo capaz de procesar imágenes y predecir su clasificación, en concreto, a partir de fotos de ropa en baja resolución es capaz de clasificarlas en diez categorías con una tasa de acierto del 90%.\n","\n","¡Esta tasa aún es mejorable, te animo a tomando este cuaderno como base probar a construir tus propias redes, con más capas o distintos parámetros para ver si logras obtener un resultado mejor!\n","\n","¡Muchas gracias!"],"metadata":{"id":"JtlRTaFz_nPq"}}]}